"""
GenAI Service for AI Insights and Chat
"""
import os
from typing import Dict, List, Optional
from app.config import settings

class GenAIService:
    """Service for interacting with GenAI APIs (OpenAI/Gemini)"""
    
    def __init__(self):
        self.use_gemini = settings.USE_GEMINI
        if self.use_gemini:
            self._init_gemini()
        else:
            self._init_openai()
    
    def _init_gemini(self):
        """Initialize Google Gemini API"""
        try:
            import google.generativeai as genai
            if settings.GEMINI_API_KEY:
                genai.configure(api_key=settings.GEMINI_API_KEY)
                preferred_model = settings.GEMINI_MODEL or "models/gemini-1.5-pro-latest"
                fallback_model = "models/gemini-1.5-flash-latest"

                try:
                    self.model = genai.GenerativeModel(preferred_model)
                    self.gemini_model_name = preferred_model
                except Exception as model_error:
                    print(
                        f"Warning: Failed to initialise Gemini model '{preferred_model}': {model_error}. "
                        f"Falling back to '{fallback_model}'."
                    )
                    self.model = genai.GenerativeModel(fallback_model)
                    self.gemini_model_name = fallback_model

                self.client = genai
            else:
                print("Warning: GEMINI_API_KEY not set, using mock responses")
                self.model = None
        except ImportError:
            print("google-generativeai not installed, using mock responses")
            self.model = None
    
    def _init_openai(self):
        """Initialize OpenAI API"""
        try:
            from openai import OpenAI
            if settings.OPENAI_API_KEY:
                self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
                self.model = "gpt-3.5-turbo"
            else:
                print("Warning: OPENAI_API_KEY not set, using mock responses")
                self.client = None
        except ImportError:
            print("openai not installed, using mock responses")
            self.client = None
    
    def generate_ai_insights(self, model_metrics: Dict, forecast_data: Dict, country_data: Dict) -> List[str]:
        """
        Generate AI insights based on model results
        Args:
            model_metrics: Training metrics from XGBoost model
            forecast_data: Forecast results
            country_data: Country demographic data
        Returns:
            List of insight strings
        """
        prompt = f"""T√¥i c√≥ m·ªôt m√¥ h√¨nh XGBoost d·ª± b√°o d√¢n s·ªë cho {country_data.get('name', 'qu·ªëc gia')}.

K·∫øt qu·∫£ m√¥ h√¨nh:
- R¬≤ Score: {model_metrics.get('val_r2', 0):.3f} ({model_metrics.get('val_r2', 0)*100:.1f}%)
- RMSE: {model_metrics.get('val_rmse', 0):.3f}%
- MAE: {model_metrics.get('val_mae', 0):.3f}%
- Bi·∫øn quan tr·ªçng nh·∫•t: {self._get_top_feature(model_metrics.get('feature_importance', {}))}

D·ªØ li·ªáu qu·ªëc gia:
- D√¢n s·ªë hi·ªán t·∫°i: {country_data.get('population', 0):,.0f}
- T·ª∑ l·ªá sinh: {country_data.get('birthRate', 0)}%
- T·ª∑ l·ªá t·ª≠: {country_data.get('deathRate', 0)}%
- Giai ƒëo·∫°n chuy·ªÉn ƒë·ªïi nh√¢n kh·∫©u: {country_data.get('stage', 0)}
- Tu·ªïi trung b√¨nh: {country_data.get('medianAge', 0)}

D·ª± b√°o:
- TƒÉng tr∆∞·ªüng d·ª± ki·∫øn: {forecast_data.get('growthRate', 0):.2f}%
- D√¢n s·ªë d·ª± ki·∫øn sau {forecast_data.get('years', 10)} nƒÉm: {forecast_data.get('finalPopulation', 0):,.0f}

H√£y vi·∫øt 3-5 g·∫°ch ƒë·∫ßu d√≤ng ph√¢n t√≠ch ng·∫Øn g·ªçn t√¨nh h√¨nh n√†y nh∆∞ m·ªôt chuy√™n gia nh√¢n kh·∫©u h·ªçc, t·∫≠p trung v√†o:
1. ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh
2. Ph√¢n t√≠ch xu h∆∞·ªõng d√¢n s·ªë
3. ƒê·ªÅ xu·∫•t ch√≠nh s√°ch (n·∫øu c·∫ßn)
4. C·∫£nh b√°o r·ªßi ro (n·∫øu c√≥)

Vi·∫øt b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu."""

        if self.use_gemini and self.model:
            return self._call_gemini(prompt)
        elif not self.use_gemini and self.client:
            return self._call_openai(prompt)
        else:
            return self._mock_insights(model_metrics, forecast_data, country_data)
    
    def chat(self, message: str, context: Optional[Dict] = None) -> str:
        """
        Chat with AI assistant
        Args:
            message: User message
            context: Optional context (country data, model results, etc.)
        Returns:
            AI response
        """
        context_str = ""
        if context:
            context_str = f"\n\nContext:\n- Country: {context.get('country', 'N/A')}\n"
            if context.get('model_metrics'):
                context_str += f"- Model R¬≤: {context['model_metrics'].get('val_r2', 0):.3f}\n"
        
        prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ ph√¢n t√≠ch d√¢n s·ªë v√† nh√¢n kh·∫©u h·ªçc. 
B·∫°n c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ d√¢n s·ªë, xu h∆∞·ªõng nh√¢n kh·∫©u, d·ª± b√°o d√¢n s·ªë, v√† c√°c ch√≠nh s√°ch li√™n quan.
{context_str}

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {message}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch chuy√™n nghi·ªáp, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu b·∫±ng ti·∫øng Vi·ªát."""

        if self.use_gemini and self.model:
            response = self._call_gemini_chat(prompt)
            return response
        elif not self.use_gemini and self.client:
            response = self._call_openai_chat(prompt)
            return response
        else:
            return self._mock_chat(message)
    
    def _call_gemini(self, prompt: str) -> List[str]:
        """Call Gemini API"""
        try:
            response = self.model.generate_content(prompt)
            text = response.text
            # Parse response into bullet points
            insights = [line.strip() for line in text.split('\n') if line.strip() and line.strip().startswith(('‚Ä¢', '-', '*', '1.', '2.', '3.'))]
            if not insights:
                insights = [text]
            return insights[:5]  # Return max 5 insights
        except Exception as e:
            print(f"Error calling Gemini: {e}")
            return ["L·ªói khi g·ªçi GenAI API. Vui l√≤ng ki·ªÉm tra API key."]
    
    def _call_openai(self, prompt: str) -> List[str]:
        """Call OpenAI API"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.7
            )
            text = response.choices[0].message.content
            insights = [line.strip() for line in text.split('\n') if line.strip() and line.strip().startswith(('‚Ä¢', '-', '*', '1.', '2.', '3.'))]
            if not insights:
                insights = [text]
            return insights[:5]
        except Exception as e:
            print(f"Error calling OpenAI: {e}")
            return ["L·ªói khi g·ªçi GenAI API. Vui l√≤ng ki·ªÉm tra API key."]
    
    def _call_gemini_chat(self, prompt: str) -> str:
        """Call Gemini for chat"""
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"Error calling Gemini: {e}")
            return "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."
    
    def _call_openai_chat(self, prompt: str) -> str:
        """Call OpenAI for chat"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error calling OpenAI: {e}")
            return "Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."
    
    def _get_top_feature(self, feature_importance: Dict) -> str:
        """Get top important feature"""
        if not feature_importance:
            return "N/A"
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        return sorted_features[0][0] if sorted_features else "N/A"
    
    def _mock_insights(self, model_metrics: Dict, forecast_data: Dict, country_data: Dict) -> List[str]:
        """Mock insights when API is not available"""
        insights = []
        r2 = model_metrics.get('val_r2', 0)
        
        if r2 > 0.9:
            insights.append(f"ü§ñ M√¥ h√¨nh AI v·ªõi ƒë·ªô ch√≠nh x√°c R¬≤={r2*100:.1f}% - ƒê·ªô ch√≠nh x√°c r·∫•t cao")
        elif r2 > 0.8:
            insights.append(f"üìä ƒê·ªô ch√≠nh x√°c R¬≤={r2*100:.1f}% - ƒê·ªô ch√≠nh x√°c cao")
        else:
            insights.append(f"üìä ƒê·ªô ch√≠nh x√°c R¬≤={r2*100:.1f}% - T·ªët")
        
        insights.append(f"‚ö° RMSE: {model_metrics.get('val_rmse', 0):.3f}% - Sai s·ªë trung b√¨nh")
        
        stage = country_data.get('stage', 3)
        if stage == 2:
            insights.append("üöÄ Giai ƒëo·∫°n b√πng n·ªï - C·∫ßn ƒë·∫ßu t∆∞ m·∫°nh")
        elif stage == 3:
            insights.append("‚ö° C∆° c·∫•u d√¢n s·ªë v√†ng - C∆° h·ªôi kinh t·∫ø l·ªõn")
        elif stage >= 4:
            insights.append("‚ö†Ô∏è Gi√† h√≥a d√¢n s·ªë - C·∫ßn ch√≠nh s√°ch h·ªó tr·ª£")
        
        growth = forecast_data.get('growthRate', 0)
        if growth > 0:
            insights.append(f"üîÆ AI d·ª± b√°o tƒÉng {growth:.2f}% trong {forecast_data.get('years', 10)} nƒÉm")
        else:
            insights.append(f"üîÆ AI d·ª± b√°o gi·∫£m {abs(growth):.2f}% trong {forecast_data.get('years', 10)} nƒÉm")
        
        return insights
    
    def _mock_chat(self, message: str) -> str:
        """Mock chat response when API is not available"""
        message_lower = message.lower()
        
        if 'd√¢n s·ªë' in message_lower or 'population' in message_lower:
            return "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ph√¢n t√≠ch d√¢n s·ªë. H√£y cho t√¥i bi·∫øt qu·ªëc gia b·∫°n mu·ªën t√¨m hi·ªÉu."
        elif 'd·ª± b√°o' in message_lower or 'forecast' in message_lower:
            return "M√¥ h√¨nh XGBoost c·ªßa ch√∫ng t√¥i s·ª≠ d·ª•ng c√°c y·∫øu t·ªë nh∆∞ t·ª∑ l·ªá sinh, t·ª≠, GDP, v√† c√°c ch·ªâ s·ªë x√£ h·ªôi ƒë·ªÉ d·ª± b√°o d√¢n s·ªë."
        elif 'm√¥ h√¨nh' in message_lower or 'model' in message_lower:
            return "Ch√∫ng t√¥i s·ª≠ d·ª•ng XGBoost, m·ªôt m√¥ h√¨nh machine learning m·∫°nh m·∫Ω ƒë·ªÉ d·ª± b√°o tƒÉng tr∆∞·ªüng d√¢n s·ªë."
        else:
            return "T√¥i hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. ƒê·ªÉ c√≥ c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n, vui l√≤ng cung c·∫•p th√™m context ho·∫∑c k·∫øt n·ªëi GenAI API."

